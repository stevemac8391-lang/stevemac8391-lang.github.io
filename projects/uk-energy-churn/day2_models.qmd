---
title: "models_day2"
format: html
---


```{r setup, include=FALSE, message=TRUE, warning=TRUE}

# Set options
options(dplyr.summarise.inform = FALSE)
knitr::opts_chunk$set(fig.width = 12, 
                      fig.height =  8,
                      include = TRUE,
                      echo = TRUE)

# Load the necessary packages
library(tidyverse)
library(dplyr)
library(here)
library(caret)
```


```{r read_data, message=FALSE, warning=FALSE}
churn <- read_csv(here('data/raw', 'Churn_Modelling.csv'))
head(churn)
```
## Data Partition for training and prediction.
```{r}
set.seed(123)

churn <- churn %>%
  mutate(Exited = factor(Exited))   # 0 = stayed, 1 = churned

train_index <- createDataPartition(churn$Exited, p = 0.8, list = FALSE)

train <- churn[train_index, ]
test  <- churn[-train_index, ]
```
The data set is spilt into two data set train and test.
Train is used to train the model and test is used to predict and compare the results
p=0.8 means the data is spilt into 80% for the train and 20% for test.

## Logistic regression  Model
```{r}
logit_model <- glm(
  Exited ~ Geography + Gender + Age + Tenure +
    NumOfProducts + IsActiveMember + CreditScore + Balance,
  data = train,
  family = binomial()
)

summary(logit_model)
```
The logistic regresssion model is run with binomial as the output is binary(0,1). The fetaures are Gender,Age,Tenure,NumOfProducts,IsActiveMember,CreditScor and Balance. 
- strong positive predictors - GeographyGermany, Age,Balance.
- strong negative predictors - GenderMale, IsActiveMember,CreditScore ??
No good predictors :GeographySpain , Tenure , NumOfProducts 
```{r}
# Predict churn probabilities on test data
test_probs <- predict(logit_model, newdata = test, type = "response")
test_pred <- ifelse(test_probs >= 0.5, "1", "0")
test_pred <- factor(test_pred, levels = c("0", "1"))
conf_mat <- confusionMatrix(test_pred, test$Exited, positive = "1")
conf_mat
conf_mat$byClass["Recall"]
conf_mat$byClass["Precision"]

```
- The threshold is kept to 0.5 to create a baseline model.
- The confusion matrix gives us , very high accuracy (82%) and good precision(67%). 
- But recall is very low at 21%
The aim is to improve the recall with acceptable precision and accuracy.

```{r}
# Predict churn probabilities on test data using threshold equal 0.3
test_probs <- predict(logit_model, newdata = test, type = "response")
test_pred <- ifelse(test_probs >= 0.3, "1", "0")
test_pred <- factor(test_pred, levels = c("0", "1"))
conf_mat <- confusionMatrix(test_pred, test$Exited, positive = "1")
conf_mat
conf_mat$byClass["Recall"]
conf_mat$byClass["Precision"]
```
- The threshold is kept to 0.3 to create as there is class imbalance of 4:1.
- The confusion matrix gives us , still a very high accuracy (79%) and reduced precision (47%). 
- But recall improves to 49%.
This is better than the logistic model with 0.5 threshold, but our aim to reach higher targetof recall close ~ 65% as a start.


## Randon forest Model
```{r}
library(randomForest)

set.seed(123)

rf_model <- randomForest(
  Exited ~ Geography + Gender + Age + Tenure +
    NumOfProducts + IsActiveMember + CreditScore + Balance,
  data       = train,
  ntree      = 300,    # number of trees
  mtry       = 3,      # no. of variables tried at each split (sqrt of 8 ≈ 3)
  importance = TRUE
)

print(rf_model)
```
Random Forest is a model that builds many decision trees and then averages their votes.
Hyper parameters
- nooftrees - 300
- Max feature per split = 3(to reduce over-fititng)


```{r}
# Probabilities for class "1" (churn)
rf_probs <- predict(rf_model, newdata = test, type = "prob")[, "1"]

# Use the same 0.3 threshold for fair comparison
rf_pred_03 <- ifelse(rf_probs >= 0.3, "1", "0")
rf_pred_03 <- factor(rf_pred_03, levels = c("0", "1"))

rf_cm_03 <- confusionMatrix(rf_pred_03, test$Exited, positive = "1")
rf_cm_03
rf_cm_03$byClass[c("Recall", "Precision")]

```
- The threshold is kept to 0.3 to create as there is class imbalance of 4:1.
- The confusion matrix gives us , very high accuracy (84%) and decent precision (59%). 
- But recall improved to 64%.
This is better than the logistic model with 0.5 and 0.3 threshold, and we have reached our intial target of ~ 65%.

## RG model with class weight to counter the imbalance 
```{r}
library(ranger)
class_weights <- c("0" = 1, "1" = 4)   # churners 4x weight
set.seed(123)

rf_w_model <- ranger(
  Exited ~ Geography + Gender + Age + Tenure +
    NumOfProducts + IsActiveMember + CreditScore + Balance,
  data       = train,
  ntree      = 300,    # number of trees
  mtry       = 3,      # no. of variables tried at each split (sqrt of 8 ≈ 3)
  probability    = TRUE,
  class.weights  = class_weights
)

print(rf_w_model)
```
Random Forest with classs weight : Ranger 
Hyper parameters
- nooftrees - 300
- Max feature per split = 3(to reduce over-fititng) builds many decision trees and then averages their votes.
- Class weight of 4:1


```{r}
rf_w_probs <- predict(rf_w_model, data = test)$predictions[, "1"]

rf_w_pred_03 <- ifelse(rf_w_probs >= 0.3, "1", "0")
rf_w_pred_03 <- factor(rf_w_pred_03, levels = c("0", "1"))

rf_w_cm_03 <- confusionMatrix(rf_w_pred_03, test$Exited, positive = "1")
rf_w_cm_03
rf_w_cm_03$byClass[c("Recall", "Precision")]
```
- The threshold is kept to 0.3 to create as there is class imbalance of 4:1.
- The confusion matrix gives us , very high accuracy(84%) and decent precision(59%). 
- But recall is better at 65%.
This is slightly better than the RG model, with our initial target of ~ 65%.

## Model Summary
- Train data (80%) to test data (20%)

| Model | Accuracy(%) | Recall(%) |Precision(%) | Verdict |
|:--|:--|:--|:--|:--|
| **Logistic Model(0.5)** | 82 | 67 | 21 | ❌ |
| **Logistic Model(0.3)** | 79 | 47 | 49 | ⚠️ |
| **Random Forest Model(0.3)** | 83 | 57 | 64 | ✅ |
| **Random Forest Model with class weights(0.3)** | 84 | 59 | 65 | ✅ |

Overall we have tuned the parameters and set Random Forest Model with class weights(0.3) as our model for best recall ith good precision and accuracy.<br>

With this model, the bank can correctly flag about 65% of churners while keeping precision close to 60%, which is a good balance for proactive retention.
---